# Default values for alfalfa.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

secret:
  name: "aws-secrets"

env:
  public:
    JOB_QUEUE_URL: http://goaws:4100/queue/local-queue1
    JOB_QUEUE_URL_1: http://goaws:4100/queue/local-queue1
    JOB_QUEUE_URL_2: http://goaws:4100/queue/local-queue2
    MONGO_URL: mongodb://mongo:27017/
    MONGO_DB_NAME: alfalfa
    LOGLEVEL: DEBUG
    NODE_ENV: production
    S3_URL: http://minio:9000
    S3_URL_EXTERNAL: http://a7ab0d31db18b4f05a69a05aa91fc2e5-555540432.us-west-2.elb.amazonaws.com:9000
    #S3_URL_EXTERNAL: AWS S3 end point url example below. See docs on obtaining url using kubectl 
    #S3_URL_EXTERNAL: http://ae7219a17bb69440bb479e2fa5c00e41-1852833633.us-west-2.elb.amazonaws.com:9000
    REDIS_HOST: redis
    S3_BUCKET: alfalfa
    REGION: us-west-1
    INFLUXDB_DB: alfalfa
    INFLUXDB_HOST: influxdb
    INFLUXDB_HTTP_AUTH_ENABLED: true

  private:
    AWS_ACCESS_KEY_ID: user
    AWS_SECRET_ACCESS_KEY: password
    INFLUXDB_ADMIN_USER: admin
    INFLUXDB_ADMIN_PASSWORD: password

# Set to google, aws, azure or docker-local
# docker-local is the docker-desktop and used for local deployments
provider: 
  name: "aws"

domain_name: "aws-test.boptest.net"

nginx_https:
  name: "nginx-https"
  enable: false
  domain_name: "aws-test.boptest.net"

tags:
  log_stack: false

cluster:
  name: "alfalfa" 

mongo:
  name:  "mongo"
  label: "mongo"
  container:
    name: "mongo"
    image: "mongo"
    resources:
      limits:
        cpu: 0.5
        memory: "1Gi"
      requests:
        cpu: 0.25
        memory: "512Mi"
    ports:
      db_port: 27017
  persistence:
    enabled: true
    storageClass: "ssd"
    size: 10Gi
    accessModes:
      - "ReadWriteOnce"

certbot:
  name:  "certbot"
  label: "certbot"
  container:
    name: "certbot"
    image: "certbot/certbot"
    resources:
      limits:
        cpu: 0.25
        memory: "512Mi"
      requests:
        cpu: 0.1
        memory: "256Mi"
  persistence:
    enabled: true
    storageClass: "ssd"
    size: 1Gi
    accessModes:
      - "ReadWriteOnce"

load_balancer:
  name: "ingress-load-balancer"
  externalTrafficPolicy: "Local"
  label: "nginx-ingress"
  ports:
    http_name: "http" 
    http_port: 80
    http_protocol: "TCP"
    http_test_name: "http-test" 
    http_test_port: 29043
    http_test_protocol: "TCP"
    https_name: "https"
    https_port: 443
    https_protocol: "TCP"
    sns_name: "sns" 
    sns_port: 9000
    sns_protocol: "TCP"
    kibana_name: "kibana"
    kibana_port: 5601
    kibana_protocol: "TCP"
    dashboard_name: "dashboard"
    dashboard_port: 8081
    dashboard_protocol: "TCP"
  loadBalancerSourceRanges: 0.0.0.0/0

nginx_ingress:
  name: "nginx-ingress"
  label: "nginx-ingress"
  container:
    name: "nginx-ingress"
    image: "nginx:1.17.8"
    resources:
      limits:
        cpu: 0.25
        memory: "1Gi"
      requests:
        cpu: 0.1
        memory: "256Mi"

redis:
  name: "redis"
  label: "redis"
  container:
    name: "redis"
    image: "redis:4.0.6"
    resources:
      limits:
        cpu: 1
        memory: "2Gi"
      requests:
        cpu: 0.5
        memory: "1Gi"
    ports:
      redis: 6379

goaws:
  name: "goaws"
  label: "goaws"
  container:
    name: "goaws"
    image: "pafortin/goaws"
    resources:
      limits:
        cpu: 0.5
        memory: "512Mi"
      requests:
        cpu: 0.25
        memory: "256Mi"
    ports:
      sns: 4100

minio:
  name: "minio"
  label: "minio"
  container:
    name: "minio"
    image: "minio/minio"
    resources:
      limits:
        cpu: 0.5
        memory: "1Gi"
      requests:
        cpu: 0.25
        memory: "256Mi"
    ports:
      s3: 9000
  persistence:
    enabled: true
    storageClass: "ssd"
    size: 100Gi
    accessModes:
      - "ReadWriteOnce"

mc:
  name: "mc"
  label: "mc"
  container:
    name: "mc"
    image: "minio/mc"
    resources:
      limits:
        cpu: 0.25
        memory: "512Mi"
      requests:
        cpu: 0.1
        memory: "256Mi"
    ports:
      s3: 9000

web:
  name: "web"
  label: "web"
  container:
    name: "web"
    image: "nrel/alfalfa-web:0.2.0"
    resources:
      limits:
        cpu: 1
        memory: "3Gi"
      requests:
        cpu: 0.5
        memory: "1Gi"
    ports:
      http: 80
      test: 29043

nginx_dashboard:
  name: "nginx-dashboard"
  label: "nginx-dashboard"
  container:
    name: "nginx-dashboard"
    image: "nginx:1.17.8"
    resources:
      limits:
        cpu: 0.25
        memory: "1Gi"
      requests:
        cpu: 0.1
        memory: "256Mi"
    ports:
      http: 8081

worker:
  name: "worker" 
  label: "worker" 
  replicas: 2
  container:
    name: "worker"
    image: "nrel/alfalfa-worker:0.2.0"
    resources:
      limits:
        cpu: 1
        memory: "4Gi"
      requests:
        cpu: 0.5
        memory: "1Gi"
    terminationGracePeriodSeconds: 3600


elastic_job:
  name: "elastic-job"
  label: "elastic-job"
  container:
    name: "elastic-job"
    image: "elasticdump/elasticsearch-dump"
    resources:
      limits:
        cpu: 0.25
        memory: "512Mi"
      requests:
        cpu: 0.1
        memory: "256Mi"

elasticsearch:
   resources:
     requests:
       cpu: "1000m"
       memory: "512Mi"
     limits:
       cpu: "1000m"
       memory: "2Gi"
   replicas: 1
   minimumMasterNodes: 1
   # https://github.com/elastic/helm-charts/issues/783
   clusterHealthCheckParams: 'wait_for_status=yellow&timeout=1s'
   persistence:
     enabled: true
   esConfig:
     elasticsearch.yml: |
       xpack.security.enabled: false
       ingest.geoip.downloader.enabled: false


filebeat:
  extraVolumeMounts: 
    - name: varlibdockeroverlay2
      mountPath: /var/lib/dockeroverlay2
      readOnly: true
  extraVolumes: 
    - hostPath:
        path: /var/lib/docker/overlay2
        #type: ""
      name: varlibdockeroverlay2
  filebeatConfig:
    filebeat.yml: |
      filebeat.inputs:
      - type: container
        paths:
          - /var/lib/docker/containers/*/*.log
          - /var/lib/docker/overlay2/*/*matlab.log
        processors:
        - add_kubernetes_metadata:
            host: ${NODE_NAME}
            matchers:
            - logs_path:
                logs_path: "/var/log/containers/"
      output.elasticsearch:
        host: '${NODE_NAME}'
        hosts: '${ELASTICSEARCH_HOSTS:elasticsearch-master:9200}'
